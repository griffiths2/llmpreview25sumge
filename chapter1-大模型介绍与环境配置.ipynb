{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94c7fc38",
   "metadata": {},
   "source": [
    "# Chapter-1 å¤§æ¨¡å‹ä»‹ç»ä¸ç¯å¢ƒé…ç½®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18b1583",
   "metadata": {},
   "source": [
    "æœ¬èŠ‚å­¦ä¹ å†…å®¹å¤§çº²\n",
    "\n",
    "- å¤§æ¨¡å‹åŸºæœ¬æ¦‚å¿µ\n",
    "  - NLPçš„ä¼ ç»Ÿä»»åŠ¡æœ‰å“ªäº›ï¼Ÿ\n",
    "  - ä»€ä¹ˆæ˜¯å¤§æ¨¡å‹ï¼Ÿ\n",
    "- å¤§æ¨¡å‹ä¸ä¼ ç»ŸNLPæ¨¡å‹ï¼ˆBertï¼‰æœ‰ä»€ä¹ˆä¸åŒï¼Ÿ\n",
    "- åŠ¨æ‰‹å®è·µ\n",
    "  - æœåŠ¡å™¨ç¯å¢ƒé…ç½®ï¼ˆtransformers, modelscopeï¼‰\n",
    "  - æ¨¡å‹ä¸‹è½½ï¼ˆHugging Face, ModelScopeï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f44441c",
   "metadata": {},
   "source": [
    "å¤§å®¶å¥½ï¼Œ\n",
    "\n",
    "æ¬¢è¿æ¥åˆ°å¤§æ¨¡å‹ä½¿ç”¨å’Œå­¦ä¹ çš„å…¥é—¨è¯¾ç¨‹ã€‚è¿™é—¨è¯¾æ˜¯ä¸ºåƒä½ ä»¬ä¸€æ ·ï¼Œåˆšåˆšè¸å…¥è®¡ç®—æœºç§‘å­¦é¢†åŸŸçš„åŒå­¦è®¾è®¡çš„ã€‚æˆ‘ä»¬ä¸ä¼šè®²éå¸¸å¤æ‚çš„ç†è®ºï¼Œè€Œæ˜¯ä»æœ€å®é™…çš„è§’åº¦å‡ºå‘ï¼Œå¸¦å¤§å®¶äº†è§£ä»€ä¹ˆæ˜¯å¤§æ¨¡å‹ï¼Œä»¥åŠå¦‚ä½•åŠ¨æ‰‹ä½¿ç”¨å®ƒä»¬ã€‚\n",
    "\n",
    "ä»Šå¤©ï¼Œæˆ‘ä»¬çš„ä¸»è¦ä»»åŠ¡æœ‰ä¸¤ä¸ªï¼š***ç¬¬ä¸€ï¼Œå»ºç«‹å¯¹å¤§æ¨¡å‹çš„åŸºæœ¬è®¤çŸ¥ï¼›ç¬¬äºŒï¼ŒæŠŠæˆ‘ä»¬å°†æ¥åšå®éªŒè¦ç”¨çš„è®¡ç®—æœºç¯å¢ƒé…ç½®å¥½ã€‚***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1854f36f",
   "metadata": {},
   "source": [
    "## 1.1 å¤§æ¨¡å‹åŸºæœ¬æ¦‚å¿µ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fd3e3c",
   "metadata": {},
   "source": [
    "åœ¨æˆ‘ä»¬ç›´æ¥è¿›å…¥â€œå¤§æ¨¡å‹â€è¿™ä¸ªè¯é¢˜ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆèŠ±å‡ åˆ†é’Ÿäº†è§£ä¸€ä¸‹å®ƒæ‰€å±çš„é¢†åŸŸï¼šè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4086f7",
   "metadata": {},
   "source": [
    "### 1.1.1 NLPçš„ä¼ ç»Ÿä»»åŠ¡æœ‰å“ªäº›ï¼Ÿ\n",
    "\n",
    "NLPï¼ŒNatural Language Processingï¼Œè‡ªç„¶è¯­è¨€å¤„ç†ï¼Œæ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒçš„ç›®æ ‡æ˜¯è®©è®¡ç®—æœºèƒ½å¤Ÿç†è§£ã€è§£é‡Šå’Œç”Ÿæˆäººç±»è¯­è¨€ã€‚NLP ç»“åˆäº†è®¡ç®—æœºç§‘å­¦ã€äººå·¥æ™ºèƒ½ã€è¯­è¨€å­¦å’Œå¿ƒç†å­¦ç­‰å¤šä¸ªå­¦ç§‘çš„çŸ¥è¯†å’ŒæŠ€æœ¯ï¼Œæ—¨åœ¨æ‰“ç ´äººç±»è¯­è¨€å’Œè®¡ç®—æœºè¯­è¨€ä¹‹é—´çš„éšœç¢ï¼Œå®ç°æ— ç¼çš„äº¤æµä¸äº’åŠ¨ã€‚\n",
    "\n",
    "åœ¨æœ€è¿‘å‡ å¹´å¤§æ¨¡å‹ç«èµ·æ¥ä¹‹å‰ï¼ŒNLPé¢†åŸŸæ˜¯ç”±å¾ˆå¤šä¸ªâ€œä¸“é¡¹æŠ€èƒ½â€ç»„æˆçš„ã€‚å°±åƒä¸€ä¸ªå…¬å¸é‡Œæœ‰ç®¡è´¢åŠ¡çš„ï¼Œæœ‰ç®¡é”€å”®çš„ï¼Œæœ‰ç®¡äººäº‹çš„ï¼Œå„å¸å…¶èŒã€‚\n",
    "\n",
    "ä¼ ç»Ÿçš„NLPä»»åŠ¡ä¸»è¦æœ‰ä¸‹é¢è¿™äº›ï¼Œæˆ‘ä¸¾å‡ ä¸ªå¤§å®¶å¯èƒ½æ¥è§¦è¿‡çš„ä¾‹å­ï¼š\n",
    "\n",
    "- æ–‡æœ¬åˆ†ç±» (Text Classification): ç»™ä¸€æ®µæ–‡æœ¬æ‰“ä¸Šé¢„è®¾çš„æ ‡ç­¾ã€‚\n",
    "```\n",
    "ä¾‹å­1ï¼šåƒåœ¾é‚®ä»¶è¯†åˆ«ã€‚ ä½ çš„é‚®ç®±è‡ªåŠ¨æŠŠä¸€å°é‚®ä»¶è¯†åˆ«ä¸ºâ€œåƒåœ¾é‚®ä»¶â€æˆ–â€œæ­£å¸¸é‚®ä»¶â€ã€‚\n",
    "ä¾‹å­2ï¼šæƒ…æ„Ÿåˆ†æã€‚ åˆ†æä¸€æ¡ç”µå½±è¯„è®ºâ€œè¿™éƒ¨ç”µå½±å¤ªæ£’äº†ï¼Œæ¼”å‘˜æ¼”æŠ€éƒ½åœ¨çº¿ï¼â€çš„æƒ…æ„Ÿæ˜¯â€œæ­£é¢â€çš„ï¼Œè¿˜æ˜¯â€œè´Ÿé¢â€çš„ã€‚\n",
    "```\n",
    "\n",
    "- å‘½åå®ä½“è¯†åˆ« (Named Entity Recognition, NER): ä»æ–‡æœ¬ä¸­æ‰¾å‡ºç‰¹å®šä¿¡æ¯ï¼Œæ¯”å¦‚äººåã€åœ°åã€ç»„ç»‡æœºæ„åç­‰ã€‚\n",
    "```\n",
    "ä¾‹å­ï¼š â€œå²è’‚å¤«Â·ä¹”å¸ƒæ–¯åœ¨åŠ åˆ©ç¦å°¼äºšå·çš„åº“æ¯”è’‚è¯ºåˆ›ç«‹äº†è‹¹æœå…¬å¸ã€‚â€\n",
    "è¿™ä¸ªä»»åŠ¡ä¼šè¯†åˆ«å‡ºï¼šå²è’‚å¤«Â·ä¹”å¸ƒæ–¯ (äººå)ï¼ŒåŠ åˆ©ç¦å°¼äºšå· (åœ°å)ï¼Œåº“æ¯”è’‚è¯º (åœ°å)ï¼Œè‹¹æœå…¬å¸ (ç»„ç»‡æœºæ„å)ã€‚è¿™åœ¨ä¿¡æ¯æå–ã€æ„å»ºçŸ¥è¯†å›¾è°±æ—¶éå¸¸æœ‰ç”¨ã€‚\n",
    "```\n",
    "\n",
    "- æœºå™¨ç¿»è¯‘ (Machine Translation): æŠŠä¸€ç§è¯­è¨€è‡ªåŠ¨ç¿»è¯‘æˆå¦ä¸€ç§è¯­è¨€ã€‚\n",
    "```\n",
    "ä¾‹å­ï¼š è¿™ä¸ªå¤§å®¶æœ€ç†Ÿæ‚‰ï¼Œæ¯”å¦‚æŠŠ \"Hello, world!\" ç¿»è¯‘æˆ â€œä½ å¥½ï¼Œä¸–ç•Œï¼â€ã€‚\n",
    "```\n",
    "\n",
    "- é—®ç­”ç³»ç»Ÿ (Question Answering): ç»™å®šä¸€ä¸ªé—®é¢˜å’Œä¸€æ®µèƒŒæ™¯ææ–™ï¼Œè®©æœºå™¨ä»ä¸­æ‰¾å‡ºç­”æ¡ˆã€‚\n",
    "```\n",
    "ä¾‹å­ï¼š èƒŒæ™¯ææ–™æ˜¯æŸäº§å“çš„è¯´æ˜ä¹¦ï¼Œä½ æé—®ï¼šâ€œè¿™æ¬¾æ‰‹æœºçš„ç”µæ± å®¹é‡æ˜¯å¤šå°‘ï¼Ÿâ€ï¼Œç³»ç»Ÿèƒ½å‡†ç¡®å›ç­”ï¼šâ€œ5000mAhâ€ã€‚\n",
    "```\n",
    "\n",
    "> æ³¨ï¼šå¦‚æœæƒ³è¦æ›´è¯¦ç»†çš„äº†è§£NLPçš„ä»»åŠ¡ï¼Œå¯å‚è€ƒ [Happy-LLM Chapter-1 NLP åŸºç¡€æ¦‚å¿µ](https://github.com/datawhalechina/happy-llm/blob/main/docs/chapter1/%E7%AC%AC%E4%B8%80%E7%AB%A0%20NLP%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5.md)\n",
    "\n",
    "åœ¨è¿‡å»ï¼Œè¦å®Œæˆä¸Šé¢ä»»ä½•ä¸€ä¸ªä»»åŠ¡ï¼Œæˆ‘ä»¬é€šå¸¸éƒ½éœ€è¦ä¸€ä¸ªä¸“é—¨ä¸ºæ­¤ä»»åŠ¡è®­ç»ƒçš„æ¨¡å‹ã€‚ä¸€ä¸ªåšç¿»è¯‘çš„æ¨¡å‹ï¼ŒåŸºæœ¬ä¸ä¼šåšæƒ…æ„Ÿåˆ†æã€‚è¿™å°±æ˜¯ä¼ ç»ŸNLPæ¨¡å‹çš„å·¥ä½œæ¨¡å¼ï¼š**ä¸“ä¸šï¼Œä¸€æ¨¡ä¸€ç”¨**ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065d297f",
   "metadata": {},
   "source": [
    "### 1.1.2 ä»€ä¹ˆæ˜¯å¤§æ¨¡å‹\n",
    "\n",
    "é‚£ä¹ˆï¼Œä»€ä¹ˆæ˜¯å¤§æ¨¡å‹ï¼ˆLarge Language Model, LLMï¼‰å‘¢ï¼Ÿä»å­—é¢ä¸Šç†è§£ï¼Œâ€œå¤§â€æ˜¯å®ƒæœ€ç›´è§‚çš„ç‰¹ç‚¹ã€‚è¿™ä¸ªâ€œå¤§â€ä½“ç°åœ¨ä¸¤ä¸ªæ–¹é¢ï¼š\n",
    "\n",
    "- å‚æ•°è§„æ¨¡å¤§ï¼š æ¨¡å‹çš„å‚æ•°é‡å·¨å¤§ï¼Œé€šå¸¸ä» 70äº¿ï¼ˆ7Bï¼‰ çº§åˆ«èµ·æ­¥ï¼Œåˆ°ç°åœ¨å·²ç»æœ‰åƒäº¿ã€ä¸‡äº¿ ï¼ˆDeepSeek-R1ï¼š671Bï¼ŒGPT-4ï¼šçº¦1.8Tï¼‰ çº§åˆ«çš„æ¨¡å‹ã€‚ä½ å¯ä»¥æŠŠå‚æ•°æƒ³è±¡æˆæ¨¡å‹å¤§è„‘ä¸­çš„ç¥ç»å…ƒè¿æ¥ç‚¹ï¼Œè¿æ¥ç‚¹è¶Šå¤šï¼Œæ¨¡å‹å°±è¶Šâ€œèªæ˜â€ï¼Œèƒ½è®°ä½å’Œå­¦ä¹ çš„çŸ¥è¯†å°±è¶Šå¤šã€‚\n",
    "- è®­ç»ƒæ•°æ®é‡å¤§ï¼š å¤§æ¨¡å‹é€šå¸¸ä½¿ç”¨äº†æµ·é‡çš„æ–‡æœ¬æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œè¿™äº›æ•°æ®å¯èƒ½åŒ…å«äº†äº’è”ç½‘ä¸Šå¤§éƒ¨åˆ†é«˜è´¨é‡çš„å…¬å¼€æ–‡æœ¬ã€‚\n",
    "\n",
    "ä½†å¤§æ¨¡å‹ä¸ä»…ä»…æ˜¯â€œå¤§â€è€Œå·²ã€‚å®ƒæ˜¯ä¸€ç§é€šç”¨çš„ã€é¢„è®­ç»ƒè¿‡çš„è¯­è¨€æ¨¡å‹ã€‚å®ƒåœ¨è®­ç»ƒæ—¶ï¼Œç›®æ ‡éå¸¸å•çº¯ï¼šæ ¹æ®å‰é¢çš„å†…å®¹ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªæœ€å¯èƒ½å‡ºç°çš„è¯ï¼ˆtokenï¼‰æ˜¯ä»€ä¹ˆã€‚\n",
    "\n",
    "> æ³¨ï¼štoken æ˜¯æŒ‡æ¨¡å‹èƒ½å¤Ÿè¯†åˆ«çš„æœ€å°å•ä½ï¼Œæ¯”å¦‚ä¸€ä¸ªå•è¯ã€ä¸€ä¸ªæ ‡ç‚¹ç¬¦å·ç­‰ã€‚åœ¨å¤§æ¨¡å‹çš„è®­ç»ƒä¸­ï¼Œæ¨¡å‹ä¼šå°†æ–‡æœ¬ä¸­çš„æ¯ä¸ª token éƒ½æ˜ å°„æˆä¸€ä¸ªæ•°å­—ï¼Œç„¶åæ¨¡å‹ä¼šæ ¹æ®è¿™äº›æ•°å­—æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªæœ€å¯èƒ½å‡ºç°çš„ tokenã€‚\n",
    "\n",
    "é€šè¿‡åœ¨æµ·é‡æ•°æ®ä¸Šæ—¥å¤ä¸€æ—¥åœ°åšè¿™ä¸ªâ€œå®Œå½¢å¡«ç©ºâ€æˆ–â€œæ¥é¾™â€æ¸¸æˆï¼Œæ¨¡å‹æ…¢æ…¢å­¦ä¼šäº†è¯­æ³•ã€äº‹å®çŸ¥è¯†ã€é€»è¾‘æ¨ç†ï¼Œç”šè‡³æŸç§ç¨‹åº¦ä¸Šçš„â€œä¸–ç•Œè§‚â€ã€‚å› ä¸ºå®ƒå­¦çš„çŸ¥è¯†æ˜¯é€šç”¨çš„ï¼Œæ‰€ä»¥å®ƒä¸å†æ˜¯ä¸Šé¢æåˆ°çš„â€œä¸“æ‰â€ï¼Œè€Œæ›´åƒä¸€ä¸ª**â€œé€šæ‰â€**ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fab20e",
   "metadata": {},
   "source": [
    "### 1.1.3 å¤§æ¨¡å‹ä¸ä¼ ç»ŸNLPæ¨¡å‹ï¼ˆå¦‚BERTï¼‰æœ‰ä»€ä¹ˆä¸åŒï¼Ÿ\n",
    "\n",
    "ä¸ºäº†è®©å¤§å®¶æ›´æ¸…æ¥šåœ°ç†è§£è¿™ç§å˜åŒ–ï¼Œæˆ‘ä»¬æ‹¿ä¸€ä¸ªéå¸¸æœ‰ä»£è¡¨æ€§çš„ä¼ ç»ŸNLPæ¨¡å‹BERTï¼Œæ¥å’Œç°åœ¨çš„å¤§æ¨¡å‹ï¼ˆæ¯”å¦‚ Qwen3 ç³»åˆ—ï¼‰åšä¸ªå¯¹æ¯”ã€‚\n",
    "\n",
    "| ç‰¹æ€§        | ä¼ ç»Ÿ NLP æ¨¡å‹ (ä»¥ BERT ä¸ºä¾‹)         | å¤§è¯­è¨€æ¨¡å‹ (ä»¥ Qwen3 ç³»åˆ—ä¸ºä¾‹)               |\n",
    "| --------- | ----------------------------- | -------------------------------- |\n",
    "| **æ¨¡å‹è§„æ¨¡**  | äº¿çº§å‚æ•° (e.g., BERT-base: 1.1 äº¿) | åäº¿åˆ°ä¸‡äº¿çº§å‚æ•° (e.g., Qwen3-235B-A22B: 2350 äº¿)   |\n",
    "| **æ ¸å¿ƒæ€æƒ³**  | ä¸“ä¸šæ¨¡å¼ï¼šé’ˆå¯¹ç‰¹å®šä»»åŠ¡è¿›è¡Œå¾®è°ƒ (Fine-tuning) | é€šç”¨æ¨¡å¼ï¼šé€šè¿‡æç¤º (Prompting) æ¥è§£å†³å„ç§ä»»åŠ¡    |\n",
    "| **ä½¿ç”¨æ–¹å¼**  | éœ€è¦åœ¨ç‰¹å®šä»»åŠ¡çš„æ•°æ®é›†ä¸Šè¿›ä¸€æ­¥è®­ç»ƒæ¨¡å‹           | åŸºæœ¬ä¸éœ€è¦é¢å¤–è®­ç»ƒï¼Œç›´æ¥é€šè¿‡ç»™æŒ‡ä»¤çš„æ–¹å¼ä½¿ç”¨           |\n",
    "| **ä»»åŠ¡çµæ´»æ€§** | ä¸€ä¸ªæ¨¡å‹ä¸»è¦æœåŠ¡ä¸€ä¸ªæˆ–å°‘æ•°å‡ ä¸ªä»»åŠ¡             | ä¸€ä¸ªæ¨¡å‹å¯ä»¥å®Œæˆå¼€æ”¾ã€å¤šæ ·çš„ä»»åŠ¡ (å¯¹è¯ã€å†™ä½œã€ç¿»è¯‘ã€å†™ä»£ç ç­‰) |\n",
    "\n",
    "ç®€å•æ¥è¯´ï¼Œæœ€å¤§çš„åŒºåˆ«åœ¨äºä½¿ç”¨èŒƒå¼çš„æ”¹å˜ï¼š\n",
    "\n",
    "- BERTï¼šåƒä¸€ä¸ªå¤§å­¦æ¯•ä¸šç”Ÿï¼ŒåŸºç¡€ä¸é”™ï¼ˆç»è¿‡äº†é¢„è®­ç»ƒï¼‰ï¼Œä½†è¦èƒœä»»æŸä¸ªå…·ä½“å·¥ä½œï¼ˆæ¯”å¦‚æƒ…æ„Ÿåˆ†æï¼‰ï¼Œè¿˜éœ€è¦å²—å‰åŸ¹è®­ï¼ˆç”¨æƒ…æ„Ÿåˆ†æçš„æ•°æ®é›†å»å¾®è°ƒï¼‰ã€‚\n",
    "- å¤§æ¨¡å‹ï¼šåƒä¸€ä¸ªç»éªŒä¸°å¯Œçš„è¡Œä¸šä¸“å®¶ï¼Œä½ ä¸éœ€è¦å†åŸ¹è®­ä»–ã€‚ä½ åªéœ€è¦ç”¨è‡ªç„¶è¯­è¨€ç»™ä»–ä¸‹è¾¾æŒ‡ä»¤ï¼ˆæˆ‘ä»¬ç§°ä¹‹ä¸ºâ€œå†™æç¤ºè¯â€ï¼‰ï¼Œä»–å°±èƒ½ç›´æ¥å¼€å§‹å·¥ä½œã€‚ä½ æƒ³è®©ä»–åšæƒ…æ„Ÿåˆ†æï¼Œå°±é—®ä»–â€œè¿™æ®µè¯æ˜¯ç§¯æçš„è¿˜æ˜¯æ¶ˆæçš„ï¼Ÿâ€ï¼›ä½ æƒ³è®©ä»–ç¿»è¯‘ï¼Œå°±è¯´â€œæŠŠè¿™å¥è¯ç¿»è¯‘æˆè‹±æ–‡â€ã€‚\n",
    "\n",
    "è¿™ç§ä»â€œå¾®è°ƒâ€åˆ°â€œæç¤ºâ€çš„è½¬å˜ï¼Œæå¤§åœ°é™ä½äº†NLPæŠ€æœ¯çš„ä½¿ç”¨é—¨æ§›ï¼Œä¹Ÿæ˜¯å¤§æ¨¡å‹å¦‚æ­¤å¼ºå¤§çš„æ ¸å¿ƒåŸå› ä¹‹ä¸€ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8dc3b8",
   "metadata": {},
   "source": [
    "## 1.2 ç¯å¢ƒé…ç½®\n",
    "\n",
    "æ¦‚å¿µéƒ¨åˆ†æˆ‘ä»¬å…ˆäº†è§£åˆ°è¿™é‡Œã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥åšç‚¹å®é™…æ“ä½œã€‚ä½œä¸ºç†å·¥ç§‘ä¸“ä¸šçš„å­¦ç”Ÿï¼ŒåŠ¨æ‰‹èƒ½åŠ›æ˜¯ç¬¬ä¸€ä½çš„ã€‚æˆ‘ä»¬å°†ä¸€æ­¥æ­¥é…ç½®å¥½ä¸€ä¸ªå¯ä»¥åœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œå¤§æ¨¡å‹çš„åŸºç¡€ç¯å¢ƒã€‚\n",
    "\n",
    "æˆ‘ä»¬å‡è®¾ä½ å·²ç»æœ‰äº†ä¸€å° Linux æœåŠ¡å™¨çš„è®¿é—®æƒé™ï¼Œå¹¶ä¸”è¿™å°æœåŠ¡å™¨é…å¤‡äº† NVIDIA çš„ GPUï¼Œå¹¶ä¸”å·²ç»å®‰è£…å¥½äº†å¯ä½¿ç”¨ CUDA åŠ é€Ÿçš„ Pytorchã€‚\n",
    "\n",
    "å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹å½“å‰çš„ CUDA ç‰ˆæœ¬ï¼š\n",
    "\n",
    "```bash\n",
    "!nvcc --version\n",
    "```\n",
    "\n",
    "å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹å½“å‰çš„ Pytorch ç‰ˆæœ¬ï¼š\n",
    "\n",
    "```bash\n",
    "!python -c \"import torch; print(torch.__version__)\"\n",
    "```\n",
    "\n",
    "æµ‹è¯•ä¸€ä¸‹ CUDA æ˜¯å¦å¯ç”¨ï¼š\n",
    "\n",
    "```bash\n",
    "!python -c \"import torch; print(torch.cuda.is_available())\"\n",
    "```\n",
    "\n",
    "å¦‚æœè¾“å‡º `True`ï¼Œåˆ™è¯´æ˜ CUDA å·²ç»æˆåŠŸé…ç½®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b26132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Thu_Mar_28_02:18:24_PDT_2024\n",
      "Cuda compilation tools, release 12.4, V12.4.131\n",
      "Build cuda_12.4.r12.4/compiler.34097967_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9757fe0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu126\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import torch; print(torch.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc23a5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import torch; print(torch.cuda.is_available())\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744c6267",
   "metadata": {},
   "source": [
    "### 1.2.1 é…ç½®æ¨¡å‹ä¸‹è½½å’Œè¿è¡Œç¯å¢ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f5b67e",
   "metadata": {},
   "source": [
    "Hugging Face æ˜¯å…¨çƒæœ€å¤§çš„æœºå™¨å­¦ä¹ æ¨¡å‹å¼€æºç¤¾åŒºï¼Œæä¾›äº†å¤§é‡é¢„è®­ç»ƒæ¨¡å‹ã€æ•°æ®é›†å’Œå·¥å…·ï¼š\n",
    "\n",
    "- æ‹¥æœ‰è¶…è¿‡50ä¸‡ä¸ªå¼€æºæ¨¡å‹\n",
    "- æä¾›å®Œæ•´çš„æ¨¡å‹è®­ç»ƒã€éƒ¨ç½²å’Œåº”ç”¨è§£å†³æ–¹æ¡ˆ\n",
    "- æ”¯æŒ Transformersã€Diffusers ç­‰ä¸»æµæ¡†æ¶\n",
    "- æœ‰å®Œå–„çš„æ–‡æ¡£å’Œç¤¾åŒºæ”¯æŒ\n",
    "\n",
    "ModelScope æ˜¯é˜¿é‡Œäº‘æ¨å‡ºçš„æ¨¡å‹å¼€æºç¤¾åŒºå¹³å°ï¼š\n",
    "\n",
    "- æä¾›ä¸­æ–‡ç”Ÿæ€ä¸‹çš„å„ç±»AIæ¨¡å‹\n",
    "- åŒ…å«NLPã€CVã€è¯­éŸ³ç­‰å¤šä¸ªé¢†åŸŸçš„é¢„è®­ç»ƒæ¨¡å‹\n",
    "- æ”¯æŒä¸€é”®éƒ¨ç½²å’Œåœ¨çº¿ä½“éªŒ\n",
    "- æä¾›æ¨¡å‹è®­ç»ƒå’Œæ¨ç†çš„å®Œæ•´å·¥å…·é“¾\n",
    "\n",
    "æ¥ä¸‹æ¥æˆ‘ä»¬å°†ä»‹ç»å¦‚ä½•åœ¨è¿™ä¸¤ä¸ªå¹³å°ä¸‹è½½å’Œä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¤§å®¶å¯ä»¥ä»»é€‰è‡ªå·±å–œæ¬¢çš„å¹³å°æˆ–æ–¹å¼ä¸‹è½½æ¨¡å‹ï½\n",
    "\n",
    "> Hugging Face : https://huggingface.co/  \n",
    "> ModelScope : https://www.modelscope.cn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91919932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é…ç½® pip é•œåƒæº\n",
    "!pip config set global.index-url https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce64709",
   "metadata": {},
   "source": [
    "#### Hugging Face ä¸‹è½½æ¨¡å‹\n",
    "\n",
    "ä½¿ç”¨`huggingface`å®˜æ–¹æä¾›çš„`huggingface-cli`å‘½ä»¤è¡Œå·¥å…·ã€‚å®‰è£…ä¾èµ–:\n",
    "\n",
    "```shell\n",
    "pip install -U huggingface_hub\n",
    "```\n",
    "\n",
    "ç„¶åæ–°å»ºpythonæ–‡ä»¶ï¼Œå¡«å…¥ä»¥ä¸‹ä»£ç ï¼Œè¿è¡Œå³å¯ã€‚\n",
    "\n",
    "- resume-downloadï¼šæ–­ç‚¹ç»­ä¸‹\n",
    "- local-dirï¼šæœ¬åœ°å­˜å‚¨è·¯å¾„ã€‚ï¼ˆlinuxç¯å¢ƒä¸‹éœ€è¦å¡«å†™ç»å¯¹è·¯å¾„ï¼‰\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "# è®¾ç½®å›½å†…ä¸‹è½½é•œåƒåœ°å€\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "# ä¸‹è½½æ¨¡å‹\n",
    "os.system('huggingface-cli download --resume-download Qwen/Qwen3-0.6B --local-dir your_path')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8daf088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# è®¾ç½®å›½å†…ä¸‹è½½é•œåƒåœ°å€\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "# ä¸‹è½½æ¨¡å‹\n",
    "os.system('huggingface-cli download --resume-download Qwen/Qwen3-0.6B --local-dir /root/autodl-tmp/model/Qwen/Qwen3-0.6B')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20523297",
   "metadata": {},
   "source": [
    "#### Modelscope\n",
    "\n",
    "ä½¿ç”¨`modelscope`ä¸­çš„`snapshot_download`å‡½æ•°ä¸‹è½½æ¨¡å‹ï¼Œç¬¬ä¸€ä¸ªå‚æ•°ä¸ºæ¨¡å‹åç§°ï¼Œå‚æ•°`cache_dir`ä¸ºæ¨¡å‹çš„ä¸‹è½½è·¯å¾„ã€‚\n",
    "\n",
    "æ³¨æ„ï¼š`cache_dir`æœ€å¥½ä¸ºç»å¯¹è·¯å¾„ã€‚\n",
    "\n",
    "å®‰è£…ä¾èµ–ï¼š\n",
    "  \n",
    "```shell\n",
    "pip install modelscope\n",
    "pip install transformers\n",
    "```\n",
    "\n",
    "åœ¨å½“å‰ç›®å½•ä¸‹æ–°å»ºpythonæ–‡ä»¶ï¼Œå¡«å…¥ä»¥ä¸‹ä»£ç ï¼Œè¿è¡Œå³å¯ã€‚\n",
    "\n",
    "```python\n",
    "from modelscope import snapshot_download, AutoModel, AutoTokenizer\n",
    "\n",
    "model_dir = snapshot_download('Qwen/Qwen3-0.6B', cache_dir='your path', revision='master')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4192dd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q modelscope transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a6f3de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /root/autodl-tmp/model/Qwen/Qwen3-0.6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-17 15:06:10,411 - modelscope - INFO - Got 10 files, start to download ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82345cc97c35405f823eb1e5176462af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 10 items:   0%|          | 0.00/10.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "548d00fa10b54a0aba160e69969fe43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [README.md]:   0%|          | 0.00/13.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0732de4e896c4b9c8a4d8294552a8c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [model.safetensors]:   0%|          | 0.00/1.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05fae691dc614b7a889cd582506112ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [merges.txt]:   0%|          | 0.00/1.59M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d595ad28024ee3842a027a6d5f6a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [LICENSE]:   0%|          | 0.00/11.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80067628bad340c3921ecce921e69d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [configuration.json]:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556d8533749144e4a30af33c5e88b579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [config.json]:   0%|          | 0.00/726 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de28ede5f554dbeaf1eeea5e79133bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [generation_config.json]:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9f23dfe2f94d388dccc4ed12a4885a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [tokenizer.json]:   0%|          | 0.00/10.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e13be4ea8d274a2d9c398466f17af437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [tokenizer_config.json]:   0%|          | 0.00/9.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac26992dddd74933ba3e196f929d68ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [vocab.json]:   0%|          | 0.00/2.65M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-17 15:07:18,863 - modelscope - INFO - Download model 'Qwen/Qwen3-0.6B' successfully.\n",
      "2025-09-17 15:07:18,866 - modelscope - INFO - Creating symbolic link [/root/autodl-tmp/model/Qwen/Qwen3-0.6B].\n"
     ]
    }
   ],
   "source": [
    "from modelscope import snapshot_download, AutoModel, AutoTokenizer\n",
    "\n",
    "model_dir = snapshot_download('Qwen/Qwen3-0.6B', cache_dir='/root/autodl-tmp/model', revision='master')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69281a07",
   "metadata": {},
   "source": [
    "æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨ transformers åº“æ¥åŠ è½½æ¨¡å‹ï¼Œå¹¶è¿›è¡Œæ¨ç†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60808da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: <think>\n",
      "å¥½çš„ï¼Œç”¨æˆ·è®©æˆ‘ä»‹ç»ä¸­å›½å°æ¹¾æ­Œæ‰‹å¼ éŸ¶æ¶µ2025è§…å…‰æ¼”å”±ä¼šã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦ç¡®è®¤æ¼”å”±ä¼šçš„å…·ä½“æ—¶é—´ï¼Œç”¨æˆ·æåˆ°çš„æ˜¯2025å¹´ï¼Œä½†å¯èƒ½éœ€è¦ç¡®è®¤æ˜¯å¦å‡†ç¡®ã€‚ä¸è¿‡ï¼Œé€šå¸¸å¼ éŸ¶æ¶µçš„æ¼”å”±ä¼šæ—¶é—´å¯èƒ½åœ¨2025å¹´ï¼Œä½†éœ€è¦æ ¸å®ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘éœ€è¦å‡†å¤‡ä»‹ç»çš„å†…å®¹ï¼ŒåŒ…æ‹¬æ¼”å”±ä¼šçš„åŸºæœ¬ä¿¡æ¯ã€å¼ éŸ¶æ¶µçš„èƒŒæ™¯ã€æ¼”å”±ä¼šçš„äº®ç‚¹ã€æ´»åŠ¨å®‰æ’ä»¥åŠå¯èƒ½çš„è§‚ä¼—æœŸå¾…ç­‰ã€‚åŒæ—¶ï¼Œè¦ç¡®ä¿ä¿¡æ¯å‡†ç¡®ï¼Œå¦‚æœæœ‰ä¸ç¡®å®šçš„åœ°æ–¹ï¼Œå¯èƒ½éœ€è¦æé†’ç”¨æˆ·ç¡®è®¤æ—¶é—´æˆ–æä¾›æ›´å¤šç»†èŠ‚ã€‚å¦å¤–ï¼Œç”¨æˆ·å¯èƒ½å¸Œæœ›äº†è§£æ¼”å”±ä¼šçš„æ„ä¹‰æˆ–è§‚ä¼—çš„ååº”ï¼Œæ‰€ä»¥å¯ä»¥é€‚å½“åŠ å…¥ç›¸å…³å…ƒç´ ã€‚æœ€åï¼Œä¿æŒå›ç­”çš„ç®€æ´å’Œä¸“ä¸šï¼Œç»“æ„æ¸…æ™°ï¼Œæ–¹ä¾¿ç”¨æˆ·å¿«é€Ÿè·å–æ‰€éœ€ä¿¡æ¯ã€‚\n",
      "</think>\n",
      "content: å¼ éŸ¶æ¶µ2025è§…å…‰æ¼”å”±ä¼šå°†äº**11æœˆ16æ—¥**åœ¨**å°åŒ—å¸‚ç«‹ç¾æœ¯é¦†**ä¸¾è¡Œã€‚ä½œä¸ºå°æ¹¾çŸ¥åæ­Œæ‰‹ï¼Œå¼ éŸ¶æ¶µä»¥å…¶æ·±æƒ…çš„éŸ³ä¹ä¸ç‹¬ç‰¹çš„è‰ºæœ¯é£æ ¼æ·±å—ç²‰ä¸å–œçˆ±ï¼Œæ­¤æ¬¡æ¼”å”±ä¼šå°†å»¶ç»­å…¶éŸ³ä¹ä¸è‰ºæœ¯çš„ç»“åˆï¼Œå±•ç°æ›´å¤šä½œå“ä¸èˆå°é­…åŠ›ã€‚\n",
      "\n",
      "**æ¼”å”±ä¼šäº®ç‚¹ï¼š**\n",
      "1. **éŸ³ä¹é˜µå®¹**ï¼šç‰¹é‚€å°æ¹¾çŸ¥åéŸ³ä¹äººã€å°æ¹¾æµè¡ŒéŸ³ä¹äººåŠå°æ¹¾æœ¬åœŸè‰ºæœ¯å®¶å‚ä¸ï¼Œä¸ºè§‚ä¼—å¸¦æ¥å¤šå…ƒåŒ–çš„éŸ³ä¹ä½“éªŒã€‚\n",
      "2. **èˆå°è¡¨ç°**ï¼šå¼ éŸ¶æ¶µå°†äº²è‡ªç™»å°ï¼Œç»“åˆèˆå°è®¾è®¡ä¸ç¯å…‰æ•ˆæœï¼Œå±•ç°ä¸ªäººé£æ ¼ä¸è‰ºæœ¯è¡¨è¾¾ã€‚\n",
      "3. **äº’åŠ¨ç¯èŠ‚**ï¼šç°åœºå¯èƒ½è®¾æœ‰éŸ³ä¹äº’åŠ¨ã€è§‚ä¼—åˆ†äº«ç¯èŠ‚ï¼Œå¢å¼ºå‚ä¸æ„Ÿã€‚\n",
      "\n",
      "**è§‚ä¼—æœŸå¾…ï¼š**\n",
      "- æ·±æƒ…çš„éŸ³ä¹ä¸èˆå°è¡¨æ¼”ï¼ŒæœŸå¾…å¼ éŸ¶æ¶µåœ¨æœ¬æ¬¡æ¼”å‡ºä¸­å±•ç°æ›´å¤šä¸ªäººé­…åŠ›ã€‚\n",
      "- å°æ¹¾æœ¬åœŸéŸ³ä¹ä¸è‰ºæœ¯çš„èåˆï¼Œä¸ºç²‰ä¸å¸¦æ¥æ›´ä¸°å¯Œçš„æ–‡åŒ–ä½“éªŒã€‚\n",
      "\n",
      "å¦‚éœ€è¿›ä¸€æ­¥äº†è§£æ¼”å”±ä¼šè¯¦æƒ…ï¼Œå¯è”ç³»å®˜æ–¹æ´»åŠ¨ä¿¡æ¯æˆ–å…³æ³¨ç¤¾äº¤åª’ä½“åŠ¨æ€ã€‚\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„transformersåº“ç»„ä»¶\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# è®¾ç½®æ¨¡å‹æœ¬åœ°è·¯å¾„\n",
    "model_name = \"/root/autodl-tmp/model/Qwen/Qwen3-0___6B\"\n",
    "\n",
    "# åŠ è½½åˆ†è¯å™¨å’Œæ¨¡å‹\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",  # è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„æ•°æ®ç±»å‹\n",
    "    device_map=\"cuda:0\",    # è‡ªåŠ¨é€‰æ‹©å¯ç”¨è®¾å¤‡(CPU/GPU)\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# å‡†å¤‡æ¨¡å‹è¾“å…¥\n",
    "prompt = \"ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸­å›½å°æ¹¾æ­Œæ‰‹å¼ éŸ¶æ¶µ2025è§…å…‰æ¼”å”±ä¼š\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=True # é€‰æ‹©æ˜¯å¦æ‰“å¼€æ·±åº¦æ¨ç†æ¨¡å¼\n",
    ")\n",
    "# å°†è¾“å…¥æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹å¯å¤„ç†çš„å¼ é‡æ ¼å¼\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# ç”Ÿæˆæ–‡æœ¬\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=32768  # è®¾ç½®æœ€å¤§ç”Ÿæˆtokenæ•°é‡\n",
    ")\n",
    "# æå–æ–°ç”Ÿæˆçš„token ID\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "\n",
    "# è§£ææ€è€ƒå†…å®¹\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    # æŸ¥æ‰¾ç»“æŸæ ‡è®°\"</think>\"çš„ä½ç½®\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "# è§£ç æ€è€ƒå†…å®¹å’Œæœ€ç»ˆå›ç­”\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "# æ‰“å°ç»“æœ\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106bbf00",
   "metadata": {},
   "source": [
    "## è¯¾åä½œä¸š\n",
    "\n",
    "è¯·åŒå­¦ä»¬è‡ªè¡Œé€‰æ‹© Hugging Face æˆ– ModelScope å¹³å°ä¸‹è½½ `Qwen/Qwen3-4B` æ¨¡å‹ï¼Œå¹¶åŠ è½½æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f6c3d2-6719-4de3-bbcc-b23f3e8f4f38",
   "metadata": {},
   "source": [
    "è¯¾åä½œä¸šä»£ç å‚è€ƒï¼š\n",
    "\n",
    "```python\n",
    "from modelscope import snapshot_download, AutoModel, AutoTokenizer\n",
    "\n",
    "model_dir = snapshot_download('Qwen/Qwen3-4B-Instruct-2507', cache_dir='/root/autodl-tmp/model', revision='master')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c61d8365-e5b9-4fcf-bdc4-b0e03ccf3bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /root/autodl-tmp/model/Qwen/Qwen3-4B-Instruct-2507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-17 15:22:15,290 - modelscope - INFO - Got 13 files, start to download ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50ad82a78cf4faea632b3c922a27c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 13 items:   0%|          | 0.00/13.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a080473bfa354a608271abb4927abdc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [generation_config.json]:   0%|          | 0.00/238 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb18a27771f48059fb8a3b172d00ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [config.json]:   0%|          | 0.00/727 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1745d18e2cc4d1f8cb50af720ff0809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [configuration.json]:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "908f496d6c824e4cb9c1efec66d96f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [LICENSE]:   0%|          | 0.00/11.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a803892f5942f5b7a86e41e56ea258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [merges.txt]:   0%|          | 0.00/1.59M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c1545bb0734bf7ab757f5c1ef3bb8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [model-00001-of-00003.safetensors]:   0%|          | 0.00/3.69G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7707aa1ed842508b1b50e78be8f6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [model-00002-of-00003.safetensors]:   0%|          | 0.00/3.71G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c00a859d804fb8a155baeea5e883a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [model-00003-of-00003.safetensors]:   0%|          | 0.00/95.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e4651d618d4773af6f97416ce37d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [model.safetensors.index.json]:   0%|          | 0.00/32.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cba25cf166a466f95f318e51e549b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [README.md]:   0%|          | 0.00/7.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21196c613dd247ae8861bb4dc53b4435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [tokenizer.json]:   0%|          | 0.00/10.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bac589c0403481dbfe17dd381f419dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [tokenizer_config.json]:   0%|          | 0.00/9.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523bb9bc126d4d5a82c012736a93fc70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [vocab.json]:   0%|          | 0.00/2.65M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-17 15:27:57,377 - modelscope - INFO - Download model 'Qwen/Qwen3-4B-Instruct-2507' successfully.\n"
     ]
    }
   ],
   "source": [
    "from modelscope import snapshot_download\n",
    "\n",
    "model_dir = snapshot_download('Qwen/Qwen3-4B-Instruct-2507', \n",
    "                              cache_dir='/root/autodl-tmp/model', \n",
    "                              revision='master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a42c4edc-bd77-407c-92cf-cd00cc83a6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3b08eba2164859863bafbd9a9c9da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: \n",
      "content: ä½ å¥½ï¼å…³äºä½ æåˆ°çš„â€œå¼ éŸ¶æ¶µâ€ï¼Œéœ€è¦æ¾„æ¸…ä¸€ä¸ªäº‹å®ï¼š**å¼ éŸ¶æ¶µå¹¶ä¸æ˜¯ä¸­å›½å°æ¹¾æ­Œæ‰‹**ï¼Œè€Œæ˜¯**ä¸­å›½å°æ¹¾çœçš„çŸ¥åå¥³æ­Œæ‰‹ã€æ¼”å‘˜**ï¼Œå¥¹å‡ºç”Ÿäºä¸­å›½å°æ¹¾çœï¼Œæ˜¯åè¯­ä¹å›ä¸­éå¸¸å…·æœ‰ä»£è¡¨æ€§çš„éŸ³ä¹äººä¹‹ä¸€ã€‚\n",
      "\n",
      "ä»¥ä¸‹æ˜¯å…³äºå¼ éŸ¶æ¶µçš„è¯¦ç»†ä»‹ç»ï¼š\n",
      "\n",
      "---\n",
      "\n",
      "### å¼ éŸ¶æ¶µï¼ˆZhang Shaohanï¼‰\n",
      "\n",
      "- **å‡ºç”Ÿæ—¥æœŸ**ï¼š1983å¹´1æœˆ15æ—¥  \n",
      "- **å‡ºç”Ÿåœ°**ï¼šä¸­å›½å°æ¹¾çœå°åŒ—å¸‚  \n",
      "- **èŒä¸š**ï¼šæ­Œæ‰‹ã€æ¼”å‘˜ã€éŸ³ä¹åˆ¶ä½œäºº  \n",
      "- **ä»£è¡¨ä½œå“**ï¼šã€Šéšå½¢çš„ç¿…è†€ã€‹ã€Šæ¬§è‹¥æ‹‰ã€‹ã€Šç»™è‡ªå·±çš„æ­Œã€‹ã€ŠåŸæ¥ä½ è¿˜è®°å¾—ã€‹ã€Šå¥¹ã€‹ã€Šçˆ±ã€‹ç­‰  \n",
      "\n",
      "---\n",
      "\n",
      "### éŸ³ä¹æˆå°±ä¸é£æ ¼\n",
      "\n",
      "å¼ éŸ¶æ¶µä»¥**æ¸…æ¾ˆçš„å—“éŸ³**å’Œ**æå…·æ„ŸæŸ“åŠ›çš„æ¼”å”±å®åŠ›**è‘—ç§°ï¼Œå¥¹çš„éŸ³ä¹é£æ ¼èåˆäº†æµè¡Œã€æ°‘è°£ã€æ‘‡æ»šå’ŒR&Bå…ƒç´ ï¼Œæƒ…æ„ŸçœŸæŒšï¼Œæ­Œè¯å¯Œæœ‰åŠ›é‡ï¼Œå°¤å…¶æ“…é•¿è¡¨è¾¾å¥³æ€§å†…å¿ƒä¸–ç•Œã€‚\n",
      "\n",
      "- **ä»£è¡¨æ­Œæ›²ã€Šéšå½¢çš„ç¿…è†€ã€‹**ï¼šè¿™é¦–æ­Œæ˜¯2005å¹´å¥¹å‘è¡Œçš„ä¸“è¾‘ã€Šæ¢¦é‡ŒèŠ±è½çŸ¥å¤šå°‘ã€‹ä¸­çš„ä¸»æ‰“æ­Œï¼Œç”±é™ˆå¤§åŠ›ä½œè¯ä½œæ›²ï¼Œæˆä¸ºåè¯­ä¹å›ç»å…¸ï¼Œå¹¿ä¸ºä¼ å”±ï¼Œæ¿€åŠ±äº†æ— æ•°äººé¢å¯¹å›°éš¾ã€å‹‡æ•¢è¿½æ¢¦ã€‚\n",
      "- å¥¹çš„éŸ³ä¹ä½œå“å¤šæ¬¡è·å¾—é‡‘æ›²å¥–æåï¼Œä¹Ÿå¤šæ¬¡è·å¾—â€œæœ€å—æ¬¢è¿å¥³æ­Œæ‰‹â€å¥–é¡¹ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### æ¼”è‰ºç»å†\n",
      "\n",
      "- **2001å¹´**ï¼šä»¥å¶åƒç»„åˆâ€œS.H.Eâ€æˆå‘˜èº«ä»½å‡ºé“ï¼ˆå®é™…ä¸ºç‹¬ç«‹å‘å±•ï¼ŒS.H.Eæ˜¯ç»„åˆï¼Œå¥¹å¹¶éæˆå‘˜ï¼‰â€”â€”**æ›´æ­£ï¼šå¼ éŸ¶æ¶µå¹¶éS.H.Eæˆå‘˜**ï¼Œå¥¹æ˜¯ä»¥ä¸ªäººæ­Œæ‰‹èº«ä»½å‡ºé“çš„ã€‚\n",
      "- **2002å¹´**ï¼šå‘è¡Œé¦–å¼ ä¸ªäººä¸“è¾‘ã€Šå¼ éŸ¶æ¶µã€‹ï¼Œæ­£å¼å¼€å¯ä¸ªäººéŸ³ä¹ç”Ÿæ¶¯ã€‚\n",
      "- å¥¹åœ¨2000å¹´ä»£ä¸­åæœŸè¿…é€Ÿèµ°çº¢ï¼Œæˆä¸ºåè¯­ä¹å›æœ€å…·ä»£è¡¨æ€§çš„â€œå®åŠ›æ´¾å¥³å£°â€ä¹‹ä¸€ã€‚\n",
      "- ä¹‹åå¥¹ä¸æ–­æ¨å‡ºæ–°ä¸“è¾‘ï¼Œå¦‚ã€Šæ¬§è‹¥æ‹‰ã€‹ã€Šç»™è‡ªå·±çš„æ­Œã€‹ã€Šçˆ±ã€‹ç­‰ï¼Œå±•ç°äº†å¥¹åœ¨éŸ³ä¹ä¸Šçš„æˆé•¿ä¸å¤šæ ·æ€§ã€‚\n",
      "- å¥¹ä¹Ÿå‚ä¸å½±è§†å‰§æ¼”å‡ºï¼Œå¦‚ã€Šæµ·è±šæ¹¾ã€‹ã€Šçˆ±æƒ…å…¬å¯“ã€‹ç­‰ï¼Œæ‹“å±•äº†ä¸ªäººå½±å“åŠ›ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### ä¸ªäººç‰¹ç‚¹\n",
      "\n",
      "- å¥¹ä»¥**åšéŸ§ã€è‡ªå¼º**çš„å½¢è±¡è‘—ç§°ï¼Œæ›¾å…¬å¼€åˆ†äº«è‡ªå·±æˆé•¿è¿‡ç¨‹ä¸­çš„æŒ«æŠ˜ä¸åšæŒã€‚\n",
      "- æ¼”å”±é£æ ¼ç‹¬ç‰¹ï¼Œå£°éŸ³ç©¿é€åŠ›å¼ºï¼Œæƒ…æ„Ÿè¡¨è¾¾ç»†è…»ã€‚\n",
      "- å¥¹åœ¨éŸ³ä¹ä¸­å¸¸å…³æ³¨å¥³æ€§æˆé•¿ã€è‡ªæˆ‘è®¤åŒã€å¿ƒç†å¥åº·ç­‰ä¸»é¢˜ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### å…¶ä»–ä¿¡æ¯\n",
      "\n",
      "- å¼ éŸ¶æ¶µåœ¨å›½é™…ä¸Šä¹Ÿæœ‰ä¸€å®šå½±å“åŠ›ï¼Œæ›¾å—é‚€å‚åŠ å›½é™…éŸ³ä¹èŠ‚ã€æ‹…ä»»å˜‰å®¾ç­‰ã€‚\n",
      "- å¥¹ç§¯ææ”¯æŒå…¬ç›Šäº‹ä¸šï¼Œå…³æ³¨é’å°‘å¹´å¿ƒç†å¥åº·ä¸å¥³æ€§æƒç›Šã€‚\n",
      "\n",
      "---\n",
      "\n",
      "âœ… æ€»ç»“ï¼š\n",
      "\n",
      "å¼ éŸ¶æ¶µæ˜¯ä¸­å›½å°æ¹¾çœçš„è‘—åå¥³æ­Œæ‰‹ï¼Œä»¥å…¶æ·±æƒ…çš„æ­Œå£°ã€çœŸæŒšçš„éŸ³ä¹è¡¨è¾¾å’Œå¼ºå¤§çš„èˆå°è¡¨ç°åŠ›ï¼Œæˆä¸ºåè¯­ä¹å›çš„é‡è¦äººç‰©ã€‚å¥¹ä¸ä»…åœ¨éŸ³ä¹ä¸Šå–å¾—æˆåŠŸï¼Œä¹Ÿåœ¨å…¬ä¼—å½¢è±¡å’Œäººæ ¼é­…åŠ›ä¸Šèµ¢å¾—äº†å¹¿æ³›å°Šé‡ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "ğŸ“Œ æ³¨æ„ï¼š  \n",
      "ä½ æåˆ°â€œä¸­å›½å°æ¹¾æ­Œæ‰‹â€æ˜¯æ­£ç¡®çš„ï¼Œå› ä¸ºå°æ¹¾æ˜¯ä¸­å›½ä¸å¯åˆ†å‰²çš„ä¸€éƒ¨åˆ†ï¼Œå¼ éŸ¶æ¶µä½œä¸ºå°æ¹¾ç±è‰ºäººï¼Œå…¶èº«ä»½å’Œæˆå°±å±äºä¸­å›½åè¯­éŸ³ä¹æ–‡åŒ–çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚\n",
      "\n",
      "å¦‚æœä½ è¿˜æƒ³äº†è§£å¥¹çš„æŸå¼ ä¸“è¾‘ã€æŸé¦–æ­Œçš„èƒŒæ™¯ï¼Œæˆ–å¥¹çš„èˆå°è¡¨æ¼”é£æ ¼ï¼Œä¹Ÿå¯ä»¥ç»§ç»­é—®æˆ‘å“¦ï¼ğŸµâœ¨\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„transformersåº“ç»„ä»¶\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# è®¾ç½®æ¨¡å‹æœ¬åœ°è·¯å¾„\n",
    "model_name = \"/root/autodl-tmp/model/Qwen/Qwen3-4B-Instruct-2507\"\n",
    "\n",
    "# åŠ è½½åˆ†è¯å™¨å’Œæ¨¡å‹\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",  # è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„æ•°æ®ç±»å‹\n",
    "    device_map=\"auto\",    # è‡ªåŠ¨é€‰æ‹©å¯ç”¨è®¾å¤‡(CPU/GPU)\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# å‡†å¤‡æ¨¡å‹è¾“å…¥\n",
    "prompt = \"ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸­å›½å°æ¹¾æ­Œæ‰‹å¼ éŸ¶æ¶µ\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=True # é€‰æ‹©æ˜¯å¦æ‰“å¼€æ·±åº¦æ¨ç†æ¨¡å¼\n",
    ")\n",
    "# å°†è¾“å…¥æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹å¯å¤„ç†çš„å¼ é‡æ ¼å¼\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# ç”Ÿæˆæ–‡æœ¬\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=32768  # è®¾ç½®æœ€å¤§ç”Ÿæˆtokenæ•°é‡\n",
    ")\n",
    "# æå–æ–°ç”Ÿæˆçš„token ID\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "\n",
    "# è§£ææ€è€ƒå†…å®¹\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    # æŸ¥æ‰¾ç»“æŸæ ‡è®°\"</think>\"çš„ä½ç½®\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "# è§£ç æ€è€ƒå†…å®¹å’Œæœ€ç»ˆå›ç­”\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "# æ‰“å°ç»“æœ\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c1c86b-0143-4b1c-a47a-5c7d32eb159f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
